# Classification

> 분류, 베이지안 확률론, Bag of Words



## Probability 

> Early Probability Theory, Bayes' Rule, Naive Bayes Classification

### Early Probability Theory

**문제**

A와 B가 주사위 게임을 해서 <u>먼저 6번</u>을 이긴 사람이 80만원을 차지하기로 했다.

<u>A가 5번</u>, <u>B가 3번</u> 이긴 후 게임이 중단되었다면 판돈을 어떻게 나눠야 하는가?



**해결**

게임이 중단되기 전까지의 성적에 따라 나누면 ⅝, ⅜ 인데 생각해보면 합리적이지 못하다.

A와 B가 <u>현재 상태에서 먼저 6번을 이길 확률</u>로 나누면 더 합리적일 것이다.

A가 승리할 확률: ½ + ¼ + ⅛ = ⅞

B가 승리할 확률: ⅛



## 베이즈 법칙 (Bayes' Rule)

### 베이즈 법칙

$$
P(A|X) = \frac{P(X|A)P(A)}{P(X)}
$$



### 예제: 암 검사 키트

**문제**

암 A에 대한 테스트 키트가 있다. 임의의 사람이 이 암에 걸릴 확률은 1%이다. 즉, 전체 인구 중 암에 걸린 사람은 1%이다. 이 암을 진단할 수 있는 키트가 있는데, <u>암에 걸린 사람은 99%의 확률로 양성 반응</u>이 나오고, <u>걸리지 않은 사람은 1%의 확률로 양성 반응</u>이 나온다. 키트 검사 결과 양성 반응이 나왔다면, 암에 걸렸을 확률은?



**해결**

암에 걸린 사건 `A`, 키트에서 양성 반응이 나온 사건을 `X`라 할 때
$$
P(X|A) = 0.99, P(A) = 0.01\\
P(X) = P(X|A)P(A) + P(X|¬A)P(¬A) = 0.0198\\
P(A|X) = \frac{P(X|A)P(A)}{P(X)} = \frac{0.99\times0.01 }{0.0198} = 0.5
$$
따라서, 키트에서 양성 반응이 나왔을 때 암에 걸렸을 확률은 50%이다.



## 나이브 베이즈 분류기 (Naive Bayes' Classification)

### 분류기

주어진 데이터가 어떤 클래스에 속하는지 알아내는 방법을 자동으로 학습하는 알고리즘



### 예제: 사탕 기계

**문제**

사탕 기계 A, B가 있다. 이 둘은 같은 종류의 사탕을 내놓지만 들어 있는 사탕의 비율이 다르다. 사탕의 개수가 매우 많아 사탕을 뽑아도 이 비율은 유지된다. 두 기계중 하나가 선택될 확률은 각각 40%, 60%이다.

| 비율 | 빨강색 | 노랑색 | 초록색 |
| :--: | :----: | :----: | :----: |
|  A   |   2    |   2    |   1    |
|  B   |   1    |   1    |   1    |

이때, 사탕 10개를 뽑아서 <u>빨강색  4개</u>, <u>노랑색 5개</u>, <u>초록색 1개</u>를 뽑았다면 이 사탕은 어느 기계에서 뽑은 것일까?



**해결**

`X`: 사탕 10개를 뽑아 그 결과를 관측한 사건

`A`: 사탕 기계 A에서 사탕을 뽑은 사건

`B`: 사탕 기계 B에서 사탕을 뽑은 사건
$$
P(A|X) : P(B|X) = \frac{P(X|A)P(A)}{P(X)}:\frac{P(X|B)P(B)}{P(X)} = P(X|A)P(A):P(X|B)P(B)
$$
A에서 빨강 4개, 노랑 5개, 초록 1개를 꺼낼 확률 = (⅖)⁴ + (⅖)⁵ + (⅕)¹ = 5.243 x 10⁻⁵

B에서 빨강 4개, 노랑 5개, 초록 1개를 꺼낼 확률 = (⅓)⁴ + (⅓)⁵ + (⅓)¹ = 1.694 x 10⁻⁵

따라서, 0.674 : 0.326



### Bag of Words (BoW)

- 자연어 데이터에 속해있는 단어들의 가방
- 딕셔너리로 단어와 빈도를 함께 표현하면 유용함